# Enhanced Dhwani Workflow - STRICT QUALITY MODE

**Version:** 2.0 (Enhanced with Strict Quality Gates)
**Date:** 2025-10-25
**Works:** 79
**Current Pass Rate:** 0% (all need enhancement)
**Target Pass Rate:** 100%

---

## üö® STRICT QUALITY REQUIREMENTS

### Validation Results (Baseline):

**Description Quality (STRICT MODE):**
- ‚úÖ Pass: 0 works (0%)
- ‚ùå Fail: 79 works (100%)
- Average score: <20/100
- **Target:** 80+/100, 0 violations

**Checkpoint Validation (6 Checkpoints):**
- ‚úÖ Pass: 0 works (0%)
- ‚ùå Fail: 79 works (100%)
- **Target:** 0 critical issues, ‚â§2 major issues

### Common Issues Found:

1. **Description violations:** 100% have forbidden boilerplate phrases
2. **Content too short:** 100% have <80 lines (target: 150+)
3. **Too few sections:** 100% have <6 sections (target: 10+)
4. **Generic content:** 100% have template/boilerplate text
5. **Missing references:** Most have <3 references

---

## MANDATORY QUALITY GATES

### Gate 1: Description Quality (STRICT)

**Criteria (ALL must pass):**
- ‚úÖ Length: 150-300 characters
- ‚úÖ Specificity score: 60+/100
- ‚úÖ Conciseness score: 60+/100
- ‚úÖ Overall score: 80+/100
- ‚úÖ Zero forbidden phrases (30+ on blacklist)
- ‚úÖ Zero filler words (or max 1-2)
- ‚úÖ Contains specific dates (actual years)
- ‚úÖ Contains proper nouns (2+ names/places)
- ‚úÖ No truncation (...)
- ‚úÖ No generic patterns

**Forbidden Phrases (Auto-Fail):**
```
"While detailed biographical information may be limited"
"scholarly value and historical importance"
"made accessible through efforts"
"contemporary scholars and interested readers"
"valuable primary source for research"
"transformative period in global history"
"is a significant work"
"Digitized from original sources"
"available on Archive.org"
"significant contribution"
"first issued in"
"authored by"
[+18 more forbidden phrases]
```

**Validation Tool:** `description-quality-validator.js`

### Gate 2: Content Checkpoints (6 Required)

**Checkpoint 1: Metadata Integrity**
- All required fields present and valid
- Title ‚â•5 chars
- Year is valid 4-digit number (1000-2025)
- Author specified
- Language specified

**Checkpoint 2: Source Verification**
- At least 1 source URL
- From trusted domains (archive.org, gutenberg.org, etc.)
- Valid URL format (https://)

**Checkpoint 3: Reference Quality**
- Minimum 3 references
- At least 2 different types (Wikipedia + OpenLibrary, etc.)
- Reference diversity score

**Checkpoint 4: Content Depth**
- Minimum 6 sections (target: 10+)
- Minimum 80 lines (target: 150+)
- Required sections present (Overview, About, Historical/Significance)

**Checkpoint 5: Content Quality (No Fluff)**
- Zero forbidden boilerplate phrases
- No generic template sections
- Specificity ratio ‚â•10% (proper nouns)
- Substantive content, not filler

**Checkpoint 6: Factual Consistency**
- Title appears in body
- Year consistency (frontmatter ‚Üî body)
- Author mentioned in body
- Internal coherence

**Pass Criteria:** 0 critical issues, ‚â§2 major issues

**Validation Tool:** `content-checkpoint-validator.js`

### Gate 3: Multi-Source Fact Verification

**Requirement:** Every factual claim must be verified from 2+ sources

**Sources (in priority order):**
1. Archive.org metadata (primary source)
2. Wikipedia (biographical, historical context)
3. Wikidata (structured data, dates)
4. OpenLibrary (bibliographic data)

**Fact-Check Log Required:**
- Author birth/death dates ‚Üí Wikipedia + Wikidata
- Publication year ‚Üí Archive.org + frontmatter
- Historical context ‚Üí Wikipedia
- Work description ‚Üí Archive.org metadata

**Validation:** Phase 2 agents must generate fact-check logs

### Gate 4: Final QA Re-Validation

**After all enhancements, re-run ALL tools:**
1. `description-quality-validator.js` ‚Üí Must show 100% pass
2. `content-checkpoint-validator.js` ‚Üí Must show 100% pass
3. `quality-scorer.js` ‚Üí Average must be 75+/100
4. `duplicate-detector.js` ‚Üí Must show 0 duplicates
5. `pd-verifier.js` ‚Üí All must be CERTAIN or LIKELY

**No exceptions - any work failing Gate 4 goes back for revision**

---

## ENHANCED 3-PHASE WORKFLOW

### PHASE 1: Validation & Enrichment (4 Parallel Agents)

**Mandatory outputs per work:**
- ‚úÖ Validated metadata (Archive.org cross-check)
- ‚úÖ 3+ quality references (Wikipedia, Wikidata, OpenLibrary)
- ‚úÖ PD status: CERTAIN or LIKELY
- ‚úÖ Correct genre (no "General", "City", etc.)
- ‚úÖ 8-15 specific tags
- ‚úÖ Author biographical data saved for Phase 2

**Quality Gate:** Works failing metadata validation are flagged for human review

---

#### Agent 1A: Archive.org Metadata Validator & Fixer (Batch A: 20 works)

**Enhanced Instructions:**

```
You are a STRICT metadata validation specialist.

For each work in batch A (works 1-20 alphabetically):

1. FETCH Archive.org metadata via API
2. COMPARE vs frontmatter (STRICT comparison):
   - Title: Must match (¬±minor variations like "The" OK)
   - Author: Must match exact spelling
   - Year: Must be within ¬±2 years (not ¬±5)
   - Language: Must match actual content
   - Subject/Genre: Must be accurate

3. FIX all discrepancies:
   - Update frontmatter with correct data from Archive.org
   - Flag major discrepancies for human review

4. VERIFY source URL works (must return 200)

5. GENERATE validation report:
   {
     "file": "work.md",
     "status": "validated" | "needs_review",
     "corrections_made": [...],
     "archive_metadata": {...},
     "issues": [...]
   }

STRICT RULES:
- NO guessing - use Archive.org metadata as ground truth
- NO accepting incorrect data - must fix or flag
- ALL source URLs must be verified working

Tools:
- Archive.org Metadata API
- HTTP status checker

Output:
- Updated markdown files (batch A)
- validation-batch-a.json
```

---

#### Agent 1B: Multi-API Reference Hunter (Batch B: 20 works)

**Enhanced Instructions:**

```
You are a comprehensive reference enrichment specialist.

For each work in batch B (works 21-40):

1. EXTRACT title and author
2. QUERY all APIs (with 1-second delays):

   Wikipedia:
   - Search for WORK title
   - Search for AUTHOR name
   - Get summary/extract for both
   - Save biographical data (birth/death dates, context)

   Wikidata:
   - Search for WORK entity
   - Search for AUTHOR entity
   - Extract structured data (Q-numbers, dates)

   OpenLibrary:
   - Search for WORK
   - Search for AUTHOR
   - Get work key and author key

   Wikisource:
   - Check if work is available

3. BUILD comprehensive references array:
   MINIMUM 3 references, TARGET 5+

   Priority order:
   1. Wikipedia: Work (if found)
   2. Wikipedia: Author (always try)
   3. Wikidata: Work (if found)
   4. Wikidata: Author (if found)
   5. OpenLibrary: Work (if found)
   6. OpenLibrary: Author (if found)
   7. Wikisource: Work (if available)

4. SAVE author biographical data for Phase 2:
   {
     "author": "Name",
     "born": "YYYY",
     "died": "YYYY",
     "wikipedia_summary": "...",
     "wikidata_id": "Q12345",
     "major_works": [...],
     "biographical_context": "..."
   }

5. UPDATE frontmatter references section

STRICT RULES:
- Minimum 3 references REQUIRED (no exceptions)
- Target 5+ for major works
- All URLs must be verified working (200 status)
- At least 2 different source types required
- Author bio data MANDATORY for Phase 2

Rate limiting: 1 second between API calls

Output:
- Updated markdown files (batch B)
- author-bios-batch-b.json
- references-batch-b.json
```

---

#### Agent 1C: PD Verification with Wikipedia Integration (Batch C: 20 works)

**Enhanced Instructions:**

```
You are a public domain verification specialist.

For each work in batch C (works 41-60):

1. EXTRACT publication year from frontmatter
2. EXTRACT author from frontmatter
3. QUERY Wikipedia for author to get death date
4. CALCULATE PD certainty:

   Rules (in order):
   a) Published <1929 ‚Üí CERTAIN (100%)
   b) Author died >95 years ago ‚Üí CERTAIN (100%)
   c) Indian work + author died >60 years ago ‚Üí LIKELY (85%)
   d) Publication >100 years old + author uncertain ‚Üí LIKELY (80%)
   e) Publication 80-100 years + author uncertain ‚Üí PROBABLE (60%)
   f) Everything else ‚Üí UNCERTAIN or REJECT

5. ADD PD metadata to frontmatter comments:
   <!-- PD Status: CERTAIN -->
   <!-- PD Rule: Published 1920, pre-1929 US cutoff -->
   <!-- Verified: 2025-10-25 -->

6. FLAG uncertain cases:
   - UNCERTAIN: needs human legal review
   - REJECT: definitely not PD

STRICT RULES:
- Only CERTAIN and LIKELY proceed to Phase 2
- PROBABLE and UNCERTAIN flagged for human review
- REJECT works are excluded from workflow
- All PD justifications must be documented

Output:
- Updated markdown files (batch C)
- pd-verification-batch-c.json
- uncertain-cases-batch-c.json (for human review)
- reject-list-batch-c.json
```

---

#### Agent 1D: Genre & Classification Expert (Batch D: 19 works)

**Enhanced Instructions:**

```
You are a classification and taxonomy specialist.

For each work in batch D (works 61-79):

1. READ work content thoroughly
2. ANALYZE subject matter from:
   - Archive.org metadata
   - Work title
   - Actual content (if available via Archive.org)

3. CORRECT genre classification:

   FORBIDDEN (auto-reject):
   - "General"
   - "City"
   - "Unknown"
   - "Literature" (too vague)

   REQUIRED:
   - 2-4 specific genres
   - Use Dhwani existing taxonomy

   Good examples:
   - ["Epic Poetry", "Buddhist Literature", "Biography"]
   - ["Medical Science", "Ayurvedic Texts"]
   - ["Historical Biography", "Mughal Period"]
   - ["Reference Literature", "Sanskrit Lexicography"]

4. GENERATE specific tags (8-15):

   Mix of:
   - Proper nouns: Author names, places, specific works (40%)
   - Specific themes/concepts (40%)
   - Time periods: specific centuries/eras (20%)

   BAD: ["general", "literature", "classical", "history"]
   GOOD: ["Kalidasa", "Sanskrit drama", "Gupta period", "Shakuntala", "Abhijnanasakuntalam", "Indian aesthetics", "classical Sanskrit poetry"]

5. ASSIGN collections (1-4):
   - Check all 48 available collections
   - Based on: language, time, genre, geography
   - Max 4 collections (don't over-tag)

STRICT RULES:
- Zero tolerance for "General", "City", "Unknown"
- Minimum 2 genres, maximum 4
- Minimum 8 tags, maximum 15
- Tags must be specific (proper nouns + specific concepts)
- Collections must be relevant (not random)

Output:
- Updated markdown files (batch D)
- classification-batch-d.json
```

---

### PHASE 2: Content Enhancement (4 Parallel Agents)

**Mandatory outputs per work:**
- ‚úÖ Description: 150-300 chars, 80+/100 score, 0 violations
- ‚úÖ Author bio: Research-based, specific dates, 3-5 paragraphs
- ‚úÖ Content: 150+ lines, 10+ sections
- ‚úÖ Zero boilerplate phrases
- ‚úÖ Fact-check log generated

**Quality Gate:** Works failing description validation (score <80) go back for revision

---

#### Agent 2A: Description & Author Bio Writer (Batch A: 20 works)

**ULTRA-STRICT Instructions:**

```
You are a scholarly content writer. Your descriptions must pass STRICT validation.

MANDATORY REQUIREMENTS:

DESCRIPTION (150-300 chars):

FORBIDDEN (will cause auto-fail):
‚ùå "While detailed biographical information may be limited"
‚ùå "scholarly value and historical importance"
‚ùå "made accessible through efforts"
‚ùå "contemporary scholars"
‚ùå "valuable primary source"
‚ùå "transformative period"
‚ùå "is a significant work"
‚ùå "Digitized from original sources"
‚ùå "available on Archive.org"
‚ùå ANY of the 30+ forbidden phrases
‚ùå Truncation with "..."
‚ùå Generic patterns

REQUIRED (must include):
‚úÖ Specific year (actual YYYY)
‚úÖ 2+ proper nouns (names, places)
‚úÖ Specific terminology (not generic)
‚úÖ Contextual information
‚úÖ What the work IS, not just that it EXISTS

DESCRIPTION FORMULA:
"[Work title] is a [specific type] [genre] composed by [author] in [year] that [specific content/purpose]. [Specific characteristic or contribution]. [Historical/cultural significance with specifics]."

EXAMPLES:

BAD (will fail):
"The Buddhacharita is a significant work on Buddhist literature. Digitized from original sources and available on Archive.org."

GOOD (will pass):
"The Buddhacharita (Acts of the Buddha) is a 2nd-century CE Sanskrit epic poem in mahakavya style narrating Gautama Buddha's life from birth to enlightenment. Composed by A≈õvagho·π£a in 28 cantos, only the first 14 survive in Sanskrit, with complete versions preserved in Chinese and Tibetan translations."

---

AUTHOR BIOGRAPHY:

Use biographical data from Phase 1 (author-bios-batch-*.json)

FORBIDDEN:
‚ùå "was a notable figure"
‚ùå "whose contributions have been preserved"
‚ùå "detailed biographical information may be limited"
‚ùå Any generic placeholder text

REQUIRED:
‚úÖ Specific birth/death dates (if known)
‚úÖ Geographic origin and cultural context
‚úÖ Specific accomplishments and works
‚úÖ Historical period and significance
‚úÖ 3-5 substantive paragraphs
‚úÖ Modern scholarly assessment

TEMPLATE:
```
## About [Full Name]

[Full Name] ([birth year]‚Äì[death year]) was a [specific role] from [place] who [major accomplishment]. Active during [specific period], [he/she] contributed significantly to [specific field] through [specific works/achievements].

[Biographical context: education, influences, cultural environment, specific events]

[Major works and their significance: list specific titles, dates, impact]

[Legacy: how work influenced later developments, modern scholarly views, contemporary relevance]
```

PROCESS:
1. Read Archive.org metadata
2. Read Wikipedia data from Phase 1
3. Read Wikidata structured data
4. Write description (150-300 chars)
5. VALIDATE with description-quality-validator.js
6. If score <80, REWRITE until passing
7. Write author bio using saved biographical data
8. Generate fact-check log

Output:
- Updated markdown files (batch A)
- description-rewrites-batch-a.json
- fact-check-log-batch-a.json
```

---

#### Agent 2B: Content Expander (Batch B: 20 works)

**Enhanced Instructions:**

```
You are a content expansion specialist. Transform 40-line stubs into 150+ line comprehensive articles.

TARGET: Minimum 150 lines, 10+ sections, ZERO boilerplate

REQUIRED SECTIONS (10 minimum):

1. ## Overview
   - 2-3 compelling paragraphs
   - Specific, contextual
   - NO boilerplate

2. ## About [Author Name]
   - Use enhanced bio from Agent 2A style
   - 3-5 paragraphs
   - Specific dates and context

3. ## Historical Context
   - Specific to time period
   - Geographic and cultural details
   - Political/intellectual environment
   - 2-3 paragraphs

4. ## The Work: Structure and Content
   - Actual organization of the work
   - Key sections or themes
   - Specific examples
   - 3-4 paragraphs

5. ## [Literary/Philosophical/Scientific] Characteristics
   - Genre-specific analysis
   - Methodology or style
   - Specific techniques
   - 2-3 paragraphs

6. ## Reception and Influence
   - Contemporary reception
   - Historical impact
   - Later interpretations
   - 2-3 paragraphs

7. ## Textual History / Editions
   - Manuscripts and editions
   - Translations
   - Editorial history
   - 1-2 paragraphs (if applicable)

8. ## Significance
   - Why this work matters
   - Contribution to field
   - Unique aspects
   - 2-3 paragraphs

9. ## Modern Relevance
   - Contemporary scholarship
   - Current interest
   - Accessibility
   - 1-2 paragraphs

10. ## Digital Preservation (brief, factual)
    - Available through [source]
    - 1 paragraph only
    - NO generic boilerplate

REMOVE these if they exist:
‚ùå Generic "Literary Significance" with template text
‚ùå Boilerplate "Digital Preservation" with standard phrases
‚ùå Any section with placeholder text

CONTENT GUIDELINES:

By work type:
- **Classical texts**: Structure, philosophical themes, commentary tradition
- **Historical works**: Sources, methodology, historiographical importance
- **Reference works**: Organization, scope, scholarly impact
- **Poetry/literature**: Literary techniques, themes, aesthetic qualities
- **Scientific/medical**: Methodology, theories, modern validation/relevance

Follow gold standards:
- /home/bhuvanesh/new-dhwani/src/content/works/buddhacharita-asvaghosha-cowell.md (369 lines)
- /home/bhuvanesh/new-dhwani/src/content/works/charaka-samhita-ayurveda-english-translation.md (357 lines)
- /home/bhuvanesh/new-dhwani/src/content/works/amarakosha-amarasimha-colebrooke-ed.md (192 lines)

STRICT RULES:
- Minimum 150 lines (target 200+)
- Minimum 10 sections
- Zero boilerplate phrases
- All facts verified (create fact-check log)
- Specific examples, not generalities

Output:
- Updated markdown files (batch B)
- expansion-report-batch-b.json
- fact-check-log-batch-b.json
```

---

#### Agent 2C: Quality Enhancement & Boilerplate Eliminator (Batch C: 20 works)

**STRICT Instructions:**

```
You are a quality enhancement specialist with ZERO TOLERANCE for boilerplate.

For each work in batch C:

1. SCAN for forbidden phrases (30+ on blacklist):
   Use description-quality-validator.js forbidden list

   EVERY instance must be removed and replaced with specific content

2. CROSS-VERIFY facts:
   - Author dates ‚Üí Wikipedia + Wikidata (must match)
   - Publication year ‚Üí Archive.org + frontmatter (must match)
   - Historical claims ‚Üí Wikipedia sources
   - Geographic references ‚Üí verified accuracy

   Create fact-check log:
   {
     "claim": "...",
     "sources": ["Wikipedia", "Archive.org"],
     "verified": true/false,
     "notes": "..."
   }

3. ENHANCE specificity:
   - Replace vague terms with specific ones
   - Add concrete examples
   - Include numbers, dates, names
   - Geographic and temporal precision

4. IMPROVE flow:
   - Add transitions between sections
   - Ensure logical progression
   - Connect ideas coherently
   - Remove repetition

5. STYLISTIC consistency:
   - Active voice preferred
   - Scholarly but accessible
   - Consistent terminology
   - Proper transliteration

6. VALIDATE with tools:
   - Run description-quality-validator.js
   - Run content-checkpoint-validator.js
   - Score must be 80+ (description)
   - Must pass checkpoints (0 critical, ‚â§2 major)

ZERO TOLERANCE LIST (must remove ALL):
[All 30+ forbidden phrases from description-quality-validator.js]

REPLACEMENT STRATEGY:
Instead of: "is a significant work"
Use: Specific statement about what it is and why it matters

Instead of: "valuable insights"
Use: Specific insights with examples

Instead of: "during a transformative period"
Use: Specific time period with context

STRICT RULES:
- NO boilerplate survives (0% tolerance)
- ALL facts cross-verified (2+ sources)
- Description score must be 80+
- Checkpoint validation must pass

Output:
- Updated markdown files (batch C)
- quality-enhancement-batch-c.json
- fact-check-log-batch-c.json
- boilerplate-removed-batch-c.json
```

---

#### Agent 2D: Final Polish & Featured Works Curator (Batch D: 19 works)

**Enhanced Instructions:**

```
You are the final polish specialist and curator.

For each work in batch D:

1. FINAL CONTENT POLISH:
   - Proofread thoroughly
   - Fix grammatical issues
   - Improve sentence flow
   - Strengthen openings and conclusions
   - Add compelling hooks

2. REFERENCE VERIFICATION:
   - Test ALL URLs (must return 200)
   - Fix broken links
   - Add alternative URLs if available
   - Ensure proper formatting

3. METADATA PERFECTION:
   - Title case correct
   - Author names formatted consistently
   - Tags alphabetically sorted
   - Collections logically ordered
   - publishDate accurate

4. VALIDATE DESCRIPTION (STRICT):
   - Run description-quality-validator.js
   - Must score 80+
   - Must have 0 critical violations
   - Rewrite if necessary

5. IDENTIFY FEATURED CANDIDATES:

   Score each work (0-100):
   - Historical significance: 0-20
   - Content depth: 0-20
   - Reference quality: 0-20
   - Cultural impact: 0-20
   - Overall quality score: 0-20

   Featured criteria (must meet ALL):
   ‚úÖ Total score ‚â•85
   ‚úÖ Description score ‚â•85
   ‚úÖ Content ‚â•200 lines
   ‚úÖ References ‚â•5
   ‚úÖ 0 violations in validation
   ‚úÖ Exceptional historical/cultural significance

   Recommend `featured: true` for top candidates

6. UPLOAD READINESS:
   - Grade A (immediate upload): Score 85+
   - Grade B (upload ready): Score 75-84
   - Grade C (minor improvements): Score 70-74
   - Grade D (needs work): Score <70

STRICT RULES:
- 100% URL verification (all must work)
- 0 grammatical errors
- Description must pass strict validation
- Only recommend featuring if truly exceptional

Output:
- Updated markdown files (batch D)
- final-polish-batch-d.json
- featured-recommendations-batch-d.json
- upload-grades-batch-d.json
```

---

### PHASE 3: Comprehensive Quality Assurance (1 Serial Agent)

**Mandatory validation (ALL must pass):**

---

#### Agent 3: Ultra-Strict QA Validator

**STRICT Instructions:**

```
You are the final quality assurance gatekeeper. ZERO TOLERANCE for failures.

COMPREHENSIVE VALIDATION PROCESS:

1. RE-RUN ALL VALIDATION TOOLS:

   ```bash
   node description-quality-validator.js /home/bhuvanesh/dhwani-new-works
   node content-checkpoint-validator.js /home/bhuvanesh/dhwani-new-works
   node quality-scorer.js /home/bhuvanesh/dhwani-new-works
   node duplicate-detector.js /home/bhuvanesh/dhwani-new-works /home/bhuvanesh/new-dhwani/src/content/works
   node pd-verifier.js /home/bhuvanesh/dhwani-new-works
   ```

2. ANALYZE RESULTS:

   MANDATORY PASS CRITERIA:
   ‚úÖ Description validation: 100% pass rate (score 80+)
   ‚úÖ Checkpoint validation: 100% pass rate (0 critical, ‚â§2 major)
   ‚úÖ Quality scores: Average 75+, no work <70
   ‚úÖ Duplicates: 0 found
   ‚úÖ PD status: 100% CERTAIN or LIKELY

   ANY FAILURE = WORK GOES BACK FOR REVISION

3. CATEGORIZE BY QUALITY:

   - **Tier 1 (85+)**: Feature-worthy ‚Üí mark `featured: true`
   - **Tier 2 (75-84)**: Upload immediately
   - **Tier 3 (70-74)**: Upload with notes
   - **Tier 4 (<70)**: REJECT - send back to Phase 2

4. CONSISTENCY CHECK:

   - Same author across works: bio must be identical
   - Related works: should cross-reference
   - No contradictions between works
   - Dates consistent across all mentions

5. GENERATE UPLOAD MANIFEST:

   For each work:
   ```json
   {
     "file": "work.md",
     "quality_score_before": 39,
     "quality_score_after": 82,
     "improvement": "+43",
     "description_score": 85,
     "checkpoint_pass": true,
     "pd_status": "CERTAIN",
     "featured": false,
     "upload_priority": 2,
     "grade": "B",
     "issues": [],
     "notes": ""
   }
   ```

6. HUMAN REVIEW LIST:

   Flag for manual review:
   - Top 10 works (spot-check quality)
   - All featured candidates (final approval)
   - Any edge cases or uncertainties
   - Works with unique characteristics

7. FINAL REPORT:

   Generate comprehensive FINAL_QA_REPORT.md with:
   - Overall statistics
   - Before/after comparison
   - Pass rates on all criteria
   - Featured works list (5-15)
   - Upload batches (priority 1, 2, 3)
   - Any issues or recommendations
   - Human review list

SUCCESS CRITERIA (ALL required):
‚úÖ Average quality: 75+/100
‚úÖ Description pass rate: 100%
‚úÖ Checkpoint pass rate: 100%
‚úÖ Zero duplicates
‚úÖ 100% PD verified
‚úÖ Zero critical violations
‚úÖ 5-15 featured candidates
‚úÖ 70+ works ready for upload

IF ANY CRITERIA FAILS:
‚Üí Send failing works back to appropriate Phase 2 agent
‚Üí Re-validate after fixes
‚Üí Repeat until 100% pass

Output:
- FINAL_QA_REPORT.md
- upload-manifest.json
- featured-works-final.json
- human-review-list.json
- improvement-analysis.json
```

---

## EXECUTION CHECKLIST

Before launching agents:

### Pre-Flight Check:
- ‚úÖ 79 works in /home/bhuvanesh/dhwani-new-works
- ‚úÖ All validation tools working
- ‚úÖ Baseline reports generated
- ‚úÖ Gold standard examples identified
- ‚úÖ Agent instructions reviewed

### Quality Gate Enforcement:
- ‚úÖ Description validator: STRICT mode (80+ required)
- ‚úÖ Checkpoint validator: 6 mandatory checkpoints
- ‚úÖ Fact-checking: 2+ source requirement
- ‚úÖ Zero tolerance: No boilerplate survives
- ‚úÖ Final QA: 100% pass rate required

### Success Metrics:
- ‚úÖ Before: 0% pass rate, 39/100 avg quality
- ‚úÖ Target: 100% pass rate, 75+/100 avg quality
- ‚úÖ Improvement: +36 points minimum
- ‚úÖ Featured: 5-15 works
- ‚úÖ Uploadable: 70+ works

---

## READY TO EXECUTE

This enhanced workflow has STRICT quality gates at every phase.

**To begin Phase 1, confirm you're ready to proceed.**
